{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### java-souce를 parsing하고 변수명을 추출한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sample : activemq (https://github.com/apache/activemq)\n",
    "* 참고 : https://en.wikipedia.org/wiki/Naming_convention_(programming)#Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd \n",
    "%matplotlib inline\n",
    "import re \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readSource(path):\n",
    "    try :\n",
    "        with open(path) as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "    except :\n",
    "        return 'file exception'\n",
    "            \n",
    "    return ''\n",
    "\n",
    "\n",
    "def removeComments(source):\n",
    "    \"\"\"\n",
    "    replacde '/* */' and '//' style comments\n",
    "    reference : http://blog.ostermiller.org/find-comment \n",
    "    comment의 열림만 있고 닫힘이 없는 경우 regex에서 hang이 걸리는 경우가 발생함 \n",
    "    이름 방지하기 위해 사용 \n",
    "    \"\"\"\n",
    "    source += '*/'\n",
    "\n",
    "    p = re.compile('(\\/\\*([^*]|[\\r\\n]|(\\*([^/]|[\\r\\n])))*\\*\\/)|(\\/\\/.*)')\n",
    "    output = p.sub(\"\", source)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def cleaningSource(source):\n",
    "    ## remove ccomments \n",
    "    source = removeComments(source)\n",
    "    \n",
    "    ## remove \"\\r\"\n",
    "    source = source.replace(\"\\r\",\"\")\n",
    "    \n",
    "    ## split by lines\n",
    "    source_lines = source.split(\"\\n\")\n",
    "    \n",
    "    return source_lines\n",
    "\n",
    "def parseSourceLines(lines):\n",
    "    variable_names = []\n",
    "    variable_set = set()\n",
    "    for line in lines:\n",
    "        vals = parseLine(line)\n",
    "        if  (vals==None): \n",
    "            continue\n",
    "        \n",
    "        for val in vals :\n",
    "            ## unique check\n",
    "            if val[0] not in variable_set:\n",
    "                variable_names.append(val)\n",
    "                variable_set.add(val[0])\n",
    "    return variable_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Variable Extract Rule ###############################\n",
    "\n",
    "def ev_equal_rule(line):\n",
    "    \"\"\"\n",
    "    변수는 변할수 있는 값이라는 전제로 값을 변하게 하는 equal(=) 연산자의 left token을 변수를 함 \n",
    "    \"\"\"\n",
    "    line = line.replace('==',' ')\n",
    "    equal_pos = line.find('=')\n",
    "    if equal_pos < 0:\n",
    "        return None\n",
    "    line = ''.join( c if (c.isalnum()) | (c=='_') else ' ' for c in line[:equal_pos] )\n",
    "    val = line.split()[-1]\n",
    "    if len(val)>0:\n",
    "        return [val]\n",
    "    return None\n",
    "\n",
    "def ev_equal_regex_rule(line):\n",
    "    \"\"\" \n",
    "    '=' 이전에 공백이나 탭이 0~3개 까지 올수 있고 \n",
    "    '=' 이전에 A-Z|a-z|0-9|_ 로 구성된 문자가 오고 \n",
    "    '=' 다음에 '<>!' 문자가 안오는 경우 \n",
    "    \"\"\"\n",
    "    regex = r\"([A-Za-z0-9\\_]+)[ \\t]{0,3}\\=[^<>!]\"\n",
    "    line += ' '\n",
    "    matches = re.finditer(regex, line)\n",
    "    names = []\n",
    "    for match in matches:\n",
    "        names.append(match.group(1))\n",
    "    return names\n",
    "\n",
    "\n",
    "##### Class Extract Rule ###############################\n",
    "def ec_prefix_regex_rule(line):\n",
    "    \"\"\"\n",
    "    'class' 단어가 오고 \n",
    "    ' '이 1글자 이상오고  \n",
    "    다음에 a-z, A-Z, _, 0-9 글자로 이루어진 단어를 class명으로 추출 \n",
    "    \"\"\"\n",
    "    regex = r\"(class) {1,3}([a-zA-Z_0-9]+)\"\n",
    "    line += ' '\n",
    "    matches = re.finditer(regex, line)\n",
    "    names = []\n",
    "    for match in matches:\n",
    "        names.append(match.group(2))\n",
    "        \n",
    "    return names \n",
    "\n",
    "def ev_regex_rule(line, regex, groupid):\n",
    "    line += ' '\n",
    "    matches = re.finditer(regex, line)\n",
    "    names = []\n",
    "    for match in matches:\n",
    "        names.append(match.group(groupid))\n",
    "    return names \n",
    "\n",
    "## 함수명을 추출하는 rule, 단순히 '('가 후미에 있고 단어가 a-z, A-Z, 0-9, _ 구성됨\n",
    "ef_bracket_regex_rule = lambda line : ev_regex_rule(line, r' {1,3}([a-zA-Z0-9]+) {0,3}\\(', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ef_braket_regex_rule(line):\n",
    "    \"\"\"\n",
    "    단순히 '('가 후미에 있고 단어가 a-z, A-Z, 0-9, _ 구성됨\n",
    "    \"\"\"\n",
    "    regex = r\"{1,3}([a-zA-Z0-9]+) {0,3}\\(\"\n",
    "    line += ' '\n",
    "    matches = re.finditer(regex, line)\n",
    "    names = []\n",
    "    for match in matches:\n",
    "        names.append(match.group(1))\n",
    "    return names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################################\n",
    "def extractVariable(line):\n",
    "    ## parse rule list \n",
    "    parse_rules = [\n",
    "        ('equal:rule', 'variable', ev_equal_regex_rule), ## equal rule by regex \n",
    "        ('class:rule', 'class', ec_prefix_regex_rule), ##\n",
    "        ('function:rule', 'function', ef_bracket_regex_rule), ##\n",
    "    ]\n",
    "    \n",
    "    val_names = []\n",
    "    for (rule, val_type, parsor) in parse_rules:\n",
    "        names = parsor(line)\n",
    "        if (names == None):\n",
    "            continue\n",
    "        for name in names:\n",
    "            val_names.append([name,val_type]) \n",
    "    \n",
    "    return val_names\n",
    "\n",
    "def extractIntent(line):\n",
    "    intent_char = ' \\t'\n",
    "    pos = 0\n",
    "    for ch in line:\n",
    "        if ch not in intent_char:\n",
    "            break\n",
    "        pos = pos + (4 if ch == '\\t' else 1)\n",
    "    return pos\n",
    "\n",
    "def parseLine(line):\n",
    "    ## check intent\n",
    "    intent = extractIntent(line)\n",
    "    \n",
    "    ## extract variables \n",
    "    vals = extractVariable(line)\n",
    "    if (vals == None) | (len(vals) == 0): \n",
    "        return None\n",
    "    \n",
    "    ret = []\n",
    "    for val in vals:\n",
    "        ## check name validation\n",
    "        if False==variableValidation(val[0]):\n",
    "            continue\n",
    "        ## add intent value \n",
    "        val.append(intent)\n",
    "        ret.append(val)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parseSourceCode(src_path):\n",
    "    source = readSource(src_path)\n",
    "    source = cleaningSource(source)\n",
    "    parsed = parseSourceLines(source)\n",
    "    \n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "\n",
    "def findFiles(path, pattern):\n",
    "    matches = []\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for filename in fnmatch.filter(filenames, pattern):\n",
    "            matches.append(os.path.join(root, filename))\n",
    "    return matches\n",
    "\n",
    "def parseSourceDir(filenames):\n",
    "    pared_variables = []\n",
    "\n",
    "    for path in filenames:\n",
    "        pared_variables.extend(parseSourceCode(path))\n",
    "    return pared_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Java 예약어 \n",
    "reserved_words = set('abstract default package synchronized boolean do if private this break double implements protected throw byte else import public throws switch enum instanceof return try catch extends int short char final interface static void class finally long strictfp volatile float native super while continue for new case goto* null transient const operator future generic ineer outer rest var from'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variableValidation(name):\n",
    "    name = name.lower()\n",
    "    ## check reserved words \n",
    "    if name in reserved_words:\n",
    "        return False\n",
    "    \n",
    "    ## check start-char is number\n",
    "    if name[0].isnumeric():\n",
    "        return False\n",
    "    \n",
    "    ## check test code's name\n",
    "    if name.find(\"test\") > -1:\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def charType(ch):\n",
    "    if ch=='_':\n",
    "        return 'underbar'\n",
    "    \n",
    "    if ch.isnumeric():\n",
    "        return 'numeric'\n",
    "    \n",
    "    if not ch.isalpha():\n",
    "        return 'unknown'\n",
    "    \n",
    "    if ch.islower():\n",
    "        return 'lower'\n",
    "    else :\n",
    "        return 'upper'\n",
    "\n",
    "    return 'unknown'\n",
    "\n",
    "def chLevel(ch):\n",
    "    if ch.islower():   return 1\n",
    "    if ch.isupper():   return 2\n",
    "    if ch.isnumeric(): return 3\n",
    "    if ch=='_':        return 4\n",
    "    if ch=='$':        return 0\n",
    "    return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parse', 'DBMXML', 'From', 'IP', 'Address']\n"
     ]
    }
   ],
   "source": [
    "def removeNumber(word):\n",
    "    removed = ''\n",
    "    for ch in word:\n",
    "        if not ch.isnumeric():\n",
    "            removed += ch\n",
    "    return removed\n",
    "\n",
    "\n",
    "## https://en.wikipedia.org/wiki/Naming_convention_(programming)#Java \n",
    "def tokenizer(sentance):\n",
    "    \"\"\" \n",
    "    naming된 sentance를 단어로 tokenizing 한다. \n",
    "    java naming convention에 기반하여 check\n",
    "    UpperCamelCase, lowerCamelCase, lower_delimiter_case, UPPER_DELIMITER_CASE \n",
    "    위의 4가지 naming convention 으로 tokenize 실행 \n",
    "    \"\"\"\n",
    "    \n",
    "    ### inspection split char posision \n",
    "    old_level = 0\n",
    "    split_pos = []\n",
    "    last_pos = 0\n",
    "    for pos, ch in enumerate(sentance):\n",
    "        cur_level = chLevel(ch)\n",
    "        if (cur_level < old_level) & (pos>1) :  ## lower edge\n",
    "            if old_level == 3: \n",
    "                split_pos.append(last_pos)\n",
    "            elif (pos - last_pos)<2:\n",
    "                split_pos.append(last_pos)\n",
    "            else :\n",
    "                split_pos.extend([last_pos,pos-1])\n",
    "            last_pos = pos\n",
    "        elif ( cur_level > old_level ): ## upper edge\n",
    "            #print('set')\n",
    "            last_pos = pos\n",
    "        old_level = cur_level\n",
    "        \n",
    "\n",
    "    ### word split \n",
    "    last_pos = 0\n",
    "    words = []\n",
    "    split_pos.append(pos+1)\n",
    "    for pos in split_pos:\n",
    "        if sentance[last_pos]=='_':\n",
    "            last_pos += 1\n",
    "        w = removeNumber(sentance[last_pos:pos])\n",
    "        if len(w)>0:\n",
    "            words.append( w )\n",
    "        last_pos=pos\n",
    "    return words \n",
    "\n",
    "\n",
    "print(tokenizer('parseDBMXMLFromIPAddress'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test']\n",
      "['token', 'Stats']\n",
      "['Active', 'MQ', 'Queue', 'Marshaller']\n",
      "['parse', 'DBMXML', 'From', 'IP', 'Address']\n",
      "['Test', 'Map', 'File']\n",
      "['TEST', 'NUMVER', 'AA']\n",
      "['my', 'number']\n"
     ]
    }
   ],
   "source": [
    "testSentance = ['test100', 'tokenStats', 'ActiveMQQueueMarshaller', \n",
    "                'parseDBMXMLFromIPAddress', 'TestMapFile', 'TEST_NUMVER_AA', 'my_number']\n",
    "for word in testSentance:\n",
    "    print(tokenizer(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^test100\n",
      "01111333\n",
      "^tokenStats\n",
      "01111121111\n",
      "^ActiveMQQueueMarshaller\n",
      "021111122211112111111111\n",
      "^parseDBMXMLFromIPAddress\n",
      "0111112222222111222111111\n",
      "^TestMapFile\n",
      "021112112111\n",
      "^TEST_NUMVER_AA\n",
      "022224222222422\n",
      "^my_number\n",
      "0114111111\n"
     ]
    }
   ],
   "source": [
    "for word in testSentance:\n",
    "    print('^'+word)\n",
    "    print(''.join(['0']+[ str(chLevel(ch)) for ch in word]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 수집 및 랭클링 작업 \n",
    "* github에서 popular fork repo download  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variable_data = {}\n",
    "variable_meta = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activemq topic 4327 files parsing start\n",
      " camel topic 14560 files parsing start\n",
      " cassandra topic 2135 files parsing start\n",
      " elasticsearch topic 5079 files parsing start\n",
      " fresco topic 678 files parsing start\n",
      " gradle topic 6239 files parsing start\n",
      " guava topic 1643 files parsing start\n",
      " hadoop topic 7673 files parsing start\n",
      " Hystrix topic 391 files parsing start\n",
      " iosched topic 378 files parsing start\n",
      " java-design-patterns topic 879 files parsing start\n",
      " kafka topic 897 files parsing start\n",
      " netty topic 2073 files parsing start\n",
      " okhttp topic 275 files parsing start\n",
      " picasso topic 76 files parsing start\n",
      " react-native topic 584 files parsing start\n",
      " retrofit topic 134 files parsing start\n",
      " RxJava topic 613 files parsing start\n",
      " spring-framework topic 6474 files parsing start\n",
      " storm topic 449 files parsing start\n",
      "parse end\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "home_dir = \"/Users/goodvc/Data/naming-recsys/resource/source/java\"\n",
    "\n",
    "\n",
    "def checkDirAndParse(output_data, ouput_meta):\n",
    "    ## check dir \n",
    "    base_dir = home_dir\n",
    "    folders = [f for f in listdir(base_dir) if isdir(join(base_dir, f))]\n",
    "    \n",
    "    for topic in folders:\n",
    "        if topic in output_data:\n",
    "            continue\n",
    "        filenames = findFiles( os.path.join(home_dir, topic) , '*.java')\n",
    "        print(\" %s topic %d files parsing start\" % (topic, len(filenames)))\n",
    "        ouput_meta[topic] = {'file_count':len(filenames)}\n",
    "        output_data[topic] = parseSourceDir(filenames)\n",
    "    print(\"parse end\")\n",
    "\n",
    "## \n",
    "checkDirAndParse(variable_data, variable_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## parsing 한 repository 기본 정보 \n",
    "repo_meta_ds = pd.DataFrame.from_dict(variable_meta, orient='index').reset_index()\n",
    "repo_meta_ds.columns = 'topic file_cnt'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 변수 Tokenize \n",
    "def tokenizeList(data_list):\n",
    "    token_list = []\n",
    "    for val in data_list:\n",
    "        tokens = tokenizer(val[0])\n",
    "        token_list.extend([[token, token.lower(),val[1], val[3]] for token in tokens if len(token)>0 ])\n",
    "    return token_list\n",
    "## 1207277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## variable data merge\n",
    "data_list = []\n",
    "for topic in variable_data.keys():\n",
    "    for info in variable_data[topic]:\n",
    "        data_list.append( info + [topic] )\n",
    "\n",
    "## variable data to dataframe \n",
    "name_ds = pd.DataFrame(data_list, columns=['name', 'kind', 'intent', 'topic'])\n",
    "\n",
    "## 단어단위로 분리하고 데이터 셋 만들기 \n",
    "naming_words = tokenizeList(data_list)\n",
    "words_ds = pd.DataFrame(naming_words, columns=['word', 'lower', 'kind', 'topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_name_ds = name_ds.groupby(['name', 'kind']).count().reset_index()[['name','kind','intent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "## POS Tagging Dataframe 생성\n",
    "analyzered = []\n",
    "for (idx,row) in unique_name_ds.iterrows():\n",
    "    word = row['name']\n",
    "    tokens = tokenizer(word)\n",
    "    tokens = [ token.lower() for token in tokens ]\n",
    "    tagged = \"+\".join([ pos for (w,pos) in nltk.pos_tag(tokens) ])\n",
    "    analyzered.append([len(tokens), tokens, tagged, row['intent']])\n",
    "\n",
    "pos_tagged_ds = pd.DataFrame(analyzered, columns=['len','tokens', 'pos', 'count'])\n",
    "pos_tagged_ds['kind'] = unique_name_ds.kind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_type='java'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 데이터셋 저장 \n",
    "name_ds.to_pickle('./resource/{type}_name_ds.pkl'.format(type=source_type))\n",
    "words_ds.to_pickle('./resource/{type}_words_ds.pkl'.format(type=source_type))\n",
    "repo_meta_ds.to_pickle('./resource/{type}_repo_ds.pkl'.format(type=source_type))\n",
    "pos_tagged_ds.to_pickle('./resource/{type}_pos_tagged_ds.pkl'.format(type=source_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parse[NN]', 'dbmxml[NN]', 'from[IN]', 'ip[NN]', 'address[NN]']\n"
     ]
    }
   ],
   "source": [
    "## sample 테스트 \n",
    "words = tokenizer('parseDBMXMLFromIPAddress')\n",
    "words = [w.lower() for w in words]\n",
    "print( [ \"%s[%s]\" %(w,pos) for (w,pos) in nltk.pos_tag(words)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추출된 네이밍 데이터 셋 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>kind</th>\n",
       "      <th>intent</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102000</th>\n",
       "      <td>          File</td>\n",
       "      <td> function</td>\n",
       "      <td>  8</td>\n",
       "      <td> cassandra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102001</th>\n",
       "      <td>      tmpIndex</td>\n",
       "      <td> variable</td>\n",
       "      <td> 12</td>\n",
       "      <td> cassandra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102002</th>\n",
       "      <td>  SSTableIndex</td>\n",
       "      <td>    class</td>\n",
       "      <td>  0</td>\n",
       "      <td> cassandra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102003</th>\n",
       "      <td>    references</td>\n",
       "      <td> variable</td>\n",
       "      <td>  4</td>\n",
       "      <td> cassandra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102004</th>\n",
       "      <td> AtomicInteger</td>\n",
       "      <td> function</td>\n",
       "      <td>  4</td>\n",
       "      <td> cassandra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name      kind  intent      topic\n",
       "102000           File  function       8  cassandra\n",
       "102001       tmpIndex  variable      12  cassandra\n",
       "102002   SSTableIndex     class       0  cassandra\n",
       "102003     references  variable       4  cassandra\n",
       "102004  AtomicInteger  function       4  cassandra"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_ds[102000:102005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>count</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td> 2</td>\n",
       "      <td>                 [affix, key]</td>\n",
       "      <td>       NN+NN</td>\n",
       "      <td> 1</td>\n",
       "      <td>    class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td> 2</td>\n",
       "      <td>             [after, effectb]</td>\n",
       "      <td>       IN+NN</td>\n",
       "      <td> 1</td>\n",
       "      <td> function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td> 2</td>\n",
       "      <td>             [after, effectl]</td>\n",
       "      <td>       IN+NN</td>\n",
       "      <td> 1</td>\n",
       "      <td> function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td> 3</td>\n",
       "      <td>    [after, evaluate, helper]</td>\n",
       "      <td>    IN+JJ+NN</td>\n",
       "      <td> 1</td>\n",
       "      <td>    class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td> 4</td>\n",
       "      <td> [after, first, sub, command]</td>\n",
       "      <td> IN+JJ+NN+NN</td>\n",
       "      <td> 1</td>\n",
       "      <td> function</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      len                        tokens          pos  count      kind\n",
       "3000    2                  [affix, key]        NN+NN      1     class\n",
       "3001    2              [after, effectb]        IN+NN      1  function\n",
       "3002    2              [after, effectl]        IN+NN      1  function\n",
       "3003    3     [after, evaluate, helper]     IN+JJ+NN      1     class\n",
       "3004    4  [after, first, sub, command]  IN+JJ+NN+NN      1  function"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagged_ds[3000:3005]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
